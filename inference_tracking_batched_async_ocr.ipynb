{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de810836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make sure to install required packages\n",
    "# !pip install ultralytics opencv-python matplotlib pillow easyocr pandas\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import threading\n",
    "import queue\n",
    "from time import time, sleep\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import easyocr\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Input options\n",
    "MODEL_PATH = \"runs/detect/train6/weights/best.pt\"\n",
    "INPUT_VIDEO_FPS = 60\n",
    "EXTRA_CAMERA_DELAY = 1  # Delay in seconds\n",
    "MAX_FRAMES = 100 # The amount of frames to process before quitting\n",
    "\n",
    "# Algorithm options\n",
    "IMAGE_SIZE = 160\n",
    "BATCH_SIZE = 100\n",
    "SKIP_FRAMES = 8 # Skip this many frames between each processing step\n",
    "TEMPORAL_CUTOFF_THRESHOLD = 15  # Amount of frames a bottle needs to be seen to be considered tracked.\n",
    "BOTTLE_DISAGREEMENT_TOLERANCE = 30  # Amount of frames the cameras can disagree before correction is applied.\n",
    "SEQUENTIAL_CORRECTION_THRESHOLD = 3 # If a tracker has to be corrected this many times in a row, it's permanently steered back on track.\n",
    "ENFORCE_INCREMENTAL_CORRECTION = False # Make sure the corrected index is unique.\n",
    "EXTRA_CORRECTION = False # Allow correcting half the feed if one half disagrees with itself.\n",
    "\n",
    "# Preview options\n",
    "PREVIEW_IMAGE_SIZE = 640\n",
    "SAVE_VIDEO = True\n",
    "EASE_DISPLAY_SPEED = True\n",
    "DISPLAY_FRAMERATE = 30\n",
    "MAX_QUEUE_SIZE = 1000 # The limit for the queue size, set to -1 to disable limit (but beware you might run out of memory then!)\n",
    "QUEUE_SIZE_CHECK_INTERVAL = 1 # Amount of seconds to wait when queue is full\n",
    "RENDER_SKIPPED_FRAMES = True\n",
    "SKIPPED_IMAGE_SIZE = 200\n",
    "\n",
    "# OCR options\n",
    "USE_OCR = True\n",
    "OCR_CONFIDENCE_THRESHOLD = 0.5\n",
    "OCR_READER = None\n",
    "OCR_RESULTS_CSV = \"bottle_ocr_results.csv\"\n",
    "OCR_FRAME_INTERVAL = 2  # Process OCR every N frames for each bottle\n",
    "OCR_MAX_ATTEMPTS_PER_BOTTLE = 50  # Maximum number of OCR attempts per bottle (to prevent infinite processing)\n",
    "\n",
    "# Logging options\n",
    "VERBOSE_YOLO = False # Show YOLO debug info\n",
    "VERBOSE_LOGS = True # Show general info\n",
    "VERBOSE_BLAB = False # Show detailed debug info\n",
    "VERBOSE_DBUG = True # Show debug info\n",
    "\n",
    "def log(*values: object, **kwargs):\n",
    "    if not VERBOSE_LOGS: return\n",
    "    print(*values, **kwargs)\n",
    "    \n",
    "def blabber(*values: object, **kwargs):\n",
    "    if not VERBOSE_BLAB: return\n",
    "    print(*values, **kwargs)\n",
    "\n",
    "def initialize_ocr():\n",
    "    \"\"\"Initialize the OCR reader\"\"\"\n",
    "    if not USE_OCR:\n",
    "        return None\n",
    "    try:\n",
    "        log(\"Initializing EasyOCR...\")\n",
    "        # Initialize EasyOCR reader\n",
    "        reader = easyocr.Reader(['en'])  # English language\n",
    "        log(\"EasyOCR initialized successfully\")\n",
    "        return reader\n",
    "    except Exception as e:\n",
    "        log(f\"Error initializing OCR: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_ocr_to_csv(bottle_id, camera_name, frame_number, ocr_text, confidence, timestamp):\n",
    "    \"\"\"Save OCR results to CSV file\"\"\"\n",
    "    csv_file = OCR_RESULTS_CSV\n",
    "    \n",
    "    # Create dataframe with new entry\n",
    "    new_entry = {\n",
    "        'bottle_id': bottle_id,\n",
    "        'camera_name': camera_name,\n",
    "        'frame_number': frame_number,\n",
    "        'ocr_text': ocr_text,\n",
    "        'confidence': confidence,\n",
    "        'timestamp': timestamp,\n",
    "        'processing_time': time()\n",
    "    }\n",
    "    \n",
    "    # Check if file exists to determine if we need to write header\n",
    "    file_exists = os.path.isfile(csv_file)\n",
    "    \n",
    "    try:\n",
    "        with open(csv_file, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=new_entry.keys())\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(new_entry)\n",
    "    except Exception as e:\n",
    "        log(f\"Error writing to CSV: {e}\")\n",
    "\n",
    "def extract_text_from_roi(reader, frame, x1, y1, x2, y2):\n",
    "    \"\"\"Extract text from a region of interest\"\"\"\n",
    "    if reader is None:\n",
    "        return \"\", 0.0\n",
    "    \n",
    "    try:\n",
    "        # Extract ROI from frame\n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        if roi.size == 0:\n",
    "            return \"\", 0.0\n",
    "        \n",
    "        # Perform OCR on the ROI\n",
    "        results = reader.readtext(roi)\n",
    "        \n",
    "        if not results:\n",
    "            return \"\", 0.0\n",
    "        \n",
    "        # Combine all detected text with confidence scores\n",
    "        combined_text = \"\"\n",
    "        total_confidence = 0.0\n",
    "        valid_results = 0\n",
    "        \n",
    "        for (bbox, text, confidence) in results:\n",
    "            if confidence >= OCR_CONFIDENCE_THRESHOLD:\n",
    "                combined_text += text + \" \"\n",
    "                total_confidence += confidence\n",
    "                valid_results += 1\n",
    "        \n",
    "        if valid_results > 0:\n",
    "            avg_confidence = total_confidence / valid_results\n",
    "            return combined_text.strip(), avg_confidence\n",
    "        else:\n",
    "            return \"\", 0.0\n",
    "            \n",
    "    except Exception as e:\n",
    "        log(f\"OCR extraction error: {e}\")\n",
    "        return \"\", 0.0\n",
    "\n",
    "class Bottle:\n",
    "    index: int = -1\n",
    "    x: float\n",
    "    y: float\n",
    "    in_view: bool = True\n",
    "    yolo_id: int\n",
    "    was_corrected: bool = False\n",
    "    ocr_texts: list = None  # Store multiple OCR results\n",
    "    best_ocr_text: str = \"\"\n",
    "    best_ocr_confidence: float = 0.0\n",
    "    ocr_attempts: int = 0\n",
    "    last_ocr_frame: int = -1\n",
    "    \n",
    "    def __init__(self, x: float, y: float, yolo_id: int):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.yolo_id = yolo_id\n",
    "        self.ocr_texts = []  # Initialize as empty list\n",
    "    \n",
    "    def add_ocr_result(self, text, confidence, frame_number):\n",
    "        \"\"\"Add OCR result and track the best one\"\"\"\n",
    "        self.ocr_attempts += 1\n",
    "        self.last_ocr_frame = frame_number\n",
    "        \n",
    "        # Store all OCR results\n",
    "        self.ocr_texts.append({\n",
    "            'text': text,\n",
    "            'confidence': confidence,\n",
    "            'frame_number': frame_number,\n",
    "            'timestamp': time()\n",
    "        })\n",
    "        \n",
    "        # Update best result if this is better\n",
    "        if confidence > self.best_ocr_confidence:\n",
    "            self.best_ocr_text = text\n",
    "            self.best_ocr_confidence = confidence\n",
    "            \n",
    "    def should_process_ocr(self, current_frame):\n",
    "        \"\"\"Determine if we should process OCR for this bottle in the current frame\"\"\"\n",
    "        if self.ocr_attempts >= OCR_MAX_ATTEMPTS_PER_BOTTLE:\n",
    "            return False\n",
    "        \n",
    "        # Process OCR at regular intervals\n",
    "        if self.last_ocr_frame == -1 or (current_frame - self.last_ocr_frame) >= OCR_FRAME_INTERVAL:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "class Camera:\n",
    "    name: str\n",
    "    video_path: str\n",
    "    output_path: str\n",
    "    cap: cv2.VideoCapture\n",
    "    out: cv2.VideoWriter\n",
    "    width: int\n",
    "    height: int\n",
    "    adjusted_width: int\n",
    "    adjusted_height: int\n",
    "    aspect_ratio: float\n",
    "    processed_frame_count: int = 0\n",
    "    model: YOLO\n",
    "    temporary_bottles: dict[int, Bottle] = {}\n",
    "    bottles: dict[int, Bottle]\n",
    "    track_ids_seen: dict[int, int] = {}  # Count of frames each track ID has been seen in\n",
    "    bottle_index_counter: int = 0\n",
    "    # start_delay: float = 0 # seconds\n",
    "    capture_fps: float\n",
    "    frames_since_last_registration: int = 0\n",
    "    last_registered_bottle: Bottle = None\n",
    "    last_registered_bottle_track_id: int = -1\n",
    "    sequential_correction_count: int = 0\n",
    "    ocr_reader: easyocr.Reader\n",
    "    \n",
    "    # frames: list[cv2.typing.MatLike]\n",
    "    # result_queue: list\n",
    "    frame_index: int\n",
    "    # last_results = None\n",
    "    \n",
    "    def get_allowed_frame_skip(self):\n",
    "        return SKIP_FRAMES if SKIP_FRAMES > 0 else 1\n",
    "    \n",
    "    def skip_frames(self, frames_to_skip: int, collect_skipped: bool = False):\n",
    "        frames = []\n",
    "        if frames_to_skip > 0:\n",
    "            for _ in range(frames_to_skip):\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    return frames\n",
    "                if collect_skipped:\n",
    "                    output_frame_width = int(SKIPPED_IMAGE_SIZE * self.aspect_ratio)\n",
    "                    output_frame_height = SKIPPED_IMAGE_SIZE\n",
    "                    output_frame = cv2.resize(frame, (output_frame_width, output_frame_height))\n",
    "                    frames.append(output_frame)\n",
    "        return frames\n",
    "    \n",
    "    def __init__(self, name: str, video_path: str, start_delay: int = 0, start_index: int = 0):\n",
    "        self.name = name\n",
    "        self.video_path = video_path\n",
    "        input_path = Path(video_path)\n",
    "        \n",
    "        self.cap = cv2.VideoCapture(video_path)\n",
    "        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.capture_fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "        self.last_results = None\n",
    "        \n",
    "        self.aspect_ratio = self.width / self.height\n",
    "        self.adjusted_width = int(IMAGE_SIZE * self.aspect_ratio)\n",
    "        self.adjusted_height = IMAGE_SIZE\n",
    "        \n",
    "        # Calculate the output video dimensions (same as display size)\n",
    "        self.output_width = int(PREVIEW_IMAGE_SIZE * self.aspect_ratio)\n",
    "        self.output_height = PREVIEW_IMAGE_SIZE\n",
    "        \n",
    "        # Initialize OCR reader for this camera\n",
    "        self.ocr_reader = OCR_READER\n",
    "        \n",
    "        if SAVE_VIDEO:\n",
    "            self.output_path = f'runs/detect/track/{input_path.stem}_tracked.mp4'\n",
    "            # Create the output directory if it doesn't exist\n",
    "            Path(self.output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            # Use the output dimensions (display size) for the video writer\n",
    "            self.out = cv2.VideoWriter(\n",
    "                self.output_path, \n",
    "                fourcc, \n",
    "                self.capture_fps / self.get_allowed_frame_skip(), \n",
    "                (self.output_width, self.output_height)\n",
    "            )\n",
    "            log(f\"Camera {self.name}: Saving video to {self.output_path} with dimensions {self.output_width}x{self.output_height}\")\n",
    "        \n",
    "        self.bottles = {}\n",
    "        self.bottle_index_counter = start_index\n",
    "        \n",
    "        start_delay += EXTRA_CAMERA_DELAY\n",
    "        frames_to_skip = int(start_delay * self.capture_fps)\n",
    "        log(f\"Camera {self.name}: Skipping first {frames_to_skip} frames for start delay of {start_delay} seconds.\")\n",
    "        self.skip_frames(frames_to_skip)\n",
    "        \n",
    "        self.processed_frame_count = 0\n",
    "        \n",
    "        blabber(\"Finished camera setup. Loading model...\")\n",
    "        self.model = YOLO(MODEL_PATH)\n",
    "        blabber(\"Finished loading model!\")\n",
    "        \n",
    "        self.results_queue = queue.Queue()\n",
    "        self.frame_queue: queue.Queue = queue.Queue()\n",
    "        self.frame_index = 0\n",
    "        self.running = False\n",
    "        self.producer_thread = None\n",
    "        self.last_output_frame: np.ndarray = None\n",
    "        \n",
    "    def get_frame(self):\n",
    "        try:\n",
    "            frame = self.frame_queue.get()\n",
    "            results = self.results_queue.get()\n",
    "            # log(f\"Camera {self.name}: Retrieved frame {self.frame_queue.qsize()} items remaining.\")\n",
    "            return frame, results\n",
    "        except queue.Empty:\n",
    "            return None, None\n",
    "    \n",
    "    def perform_ocr_on_bottle(self, frame, bottle, x1, y1, x2, y2):\n",
    "        \"\"\"Perform OCR on a bottle region and update bottle object\"\"\"\n",
    "        if not USE_OCR or self.ocr_reader is None:\n",
    "            return\n",
    "        \n",
    "        # Check if we should process OCR for this bottle in this frame\n",
    "        if not bottle.should_process_ocr(self.processed_frame_count):\n",
    "            return\n",
    "        \n",
    "        # Expand ROI slightly to capture more context\n",
    "        expansion = 10\n",
    "        x1_exp = max(0, x1 - expansion)\n",
    "        y1_exp = max(0, y1 - expansion)\n",
    "        x2_exp = min(frame.shape[1], x2 + expansion)\n",
    "        y2_exp = min(frame.shape[0], y2 + expansion)\n",
    "        \n",
    "        ocr_text, confidence = extract_text_from_roi(self.ocr_reader, frame, x1_exp, y1_exp, x2_exp, y2_exp)\n",
    "        \n",
    "        # Always add OCR result if we found something (even low confidence)\n",
    "        if ocr_text:  # Only add if we actually found text\n",
    "            bottle.add_ocr_result(ocr_text, confidence, self.processed_frame_count)\n",
    "            \n",
    "            # Save resutls to CSV if we have meaningful text with reasonable confidence\n",
    "            if confidence >= OCR_CONFIDENCE_THRESHOLD:\n",
    "                save_ocr_to_csv(\n",
    "                    bottle_id=bottle.index,\n",
    "                    camera_name=self.name,\n",
    "                    frame_number=self.processed_frame_count,\n",
    "                    ocr_text=ocr_text,\n",
    "                    confidence=confidence,\n",
    "                    timestamp=time()\n",
    "                )\n",
    "                if VERBOSE_DBUG:\n",
    "                    log(f\"Camera {self.name}: Bottle {bottle.index} OCR [{bottle.ocr_attempts}]: '{ocr_text}' (confidence: {confidence:.2f})\")\n",
    "    \n",
    "    def render_frame(self):\n",
    "        frame, results = self.get_frame()\n",
    "        if frame is None or results is None:\n",
    "            return None\n",
    "        \n",
    "        output_frame_width = int(PREVIEW_IMAGE_SIZE * self.aspect_ratio)\n",
    "        output_frame_height = PREVIEW_IMAGE_SIZE\n",
    "        \n",
    "        frame = cv2.resize(frame, (output_frame_width, output_frame_height))\n",
    "        x_scale = output_frame_width / self.adjusted_width\n",
    "        y_scale = output_frame_height / self.adjusted_height\n",
    "        \n",
    "        blabber(f\"I got {len(results)} results? Yes bru\")\n",
    "        \n",
    "        for result in results:\n",
    "            if result.boxes is not None:\n",
    "                boxes = result.boxes.xywh.cpu()\n",
    "                self.track_ids = None\n",
    "                if result.boxes.id is not None:\n",
    "                    self.track_ids = result.boxes.id.cpu().numpy().astype(int)\n",
    "                \n",
    "                cv2.putText(frame, 'Camera: ' + self.name, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                \n",
    "                for box_index, box in enumerate(boxes):\n",
    "                    x_center, y_center, box_width, box_height = box\n",
    "                    \n",
    "                    if self.track_ids is not None:\n",
    "                        track_id = self.track_ids[box_index]\n",
    "                        \n",
    "                        if self.register_bottle(x_center, y_center, track_id):\n",
    "                            log(\"Bottle got accepted as being new.\")\n",
    "                        \n",
    "                        # Render box on frame\n",
    "                        scaled_x_center = int(x_center * x_scale)\n",
    "                        scaled_y_center = int(y_center * y_scale)\n",
    "                        scaled_box_width = int(box_width * x_scale)\n",
    "                        scaled_box_height = int(box_height * y_scale)\n",
    "                        \n",
    "                        x1 = int(scaled_x_center - scaled_box_width / 2)\n",
    "                        y1 = int(scaled_y_center - scaled_box_height / 2)\n",
    "                        x2 = int(scaled_x_center + scaled_box_width / 2)\n",
    "                        y2 = int(scaled_y_center + scaled_box_height / 2)\n",
    "                        \n",
    "                        # Ensure coordinates are within frame bounds\n",
    "                        x1 = max(0, min(x1, output_frame_width - 1))\n",
    "                        y1 = max(0, min(y1, output_frame_height - 1))\n",
    "                        x2 = max(0, min(x2, output_frame_width - 1))\n",
    "                        y2 = max(0, min(y2, output_frame_height - 1))\n",
    "                        \n",
    "                        thickness = 2\n",
    "                        color = (255, 0, 0)\n",
    "                        cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
    "                        \n",
    "                        # Perform OCR on this bottle (runs continuously)\n",
    "                        bottle = None\n",
    "                        if track_id in self.bottles:\n",
    "                            bottle = self.bottles[track_id]\n",
    "                            # Perform OCR (will run at intervals based on OCR_FRAME_INTERVAL)\n",
    "                            self.perform_ocr_on_bottle(frame, bottle, x1, y1, x2, y2)\n",
    "                        \n",
    "                        def draw_bottle_id(color):\n",
    "                            cv2.putText(frame, 'Bottle ' + str(bottle.index), (int(x1 + 10), int(y1 + 30)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "                            \n",
    "                            # Display best OCR text if available\n",
    "                            if bottle and bottle.best_ocr_text and bottle.best_ocr_confidence > OCR_CONFIDENCE_THRESHOLD:\n",
    "                                ocr_display = f\"OCR: {bottle.best_ocr_text[:20]}...\" if len(bottle.best_ocr_text) > 20 else f\"OCR: {bottle.best_ocr_text}\"\n",
    "                                cv2.putText(frame, ocr_display, (int(x1 + 10), int(y1 + 60)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "                                # Also show attempt count\n",
    "                                cv2.putText(frame, f\"Attempts: {bottle.ocr_attempts}\", (int(x1 + 10), int(y1 + 80)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "                        \n",
    "                        if track_id in self.temporary_bottles:\n",
    "                            bottle = self.temporary_bottles[track_id]\n",
    "                            draw_bottle_id((0, 0, 255))\n",
    "                        if track_id in self.bottles:\n",
    "                            bottle = self.bottles[track_id]\n",
    "                            draw_bottle_id((255, 255, 0) if bottle.was_corrected else (0, 255, 0))\n",
    "                \n",
    "        \n",
    "        if VERBOSE_DBUG:\n",
    "            cv2.putText(frame, f'Queue size: {self.frame_queue.qsize()}', (10, output_frame_height - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)        \n",
    "        \n",
    "        self.last_output_frame = frame\n",
    "        \n",
    "        if SAVE_VIDEO and self.out is not None:\n",
    "            try:\n",
    "                self.out.write(frame)\n",
    "                if self.processed_frame_count % 30 == 0:  # Log every 30 frames\n",
    "                    log(f\"Camera {self.name}: Saved frame {self.processed_frame_count} to video\")\n",
    "            except Exception as e:\n",
    "                log(f\"Error writing frame to video: {e}\")\n",
    "            \n",
    "        self.finish_frame()\n",
    "        return self.last_output_frame\n",
    "        \n",
    "    def get_ready_frames_count(self):\n",
    "        return self.frame_queue.qsize()\n",
    "    \n",
    "    def _image_processing_worker(self):\n",
    "        blabber(\"Starting batch preprocessing.\")\n",
    "        while self.running:\n",
    "            finished = self.preprocess_frames(BATCH_SIZE)\n",
    "            blabber(f\"Processed a batch of {BATCH_SIZE} images\")\n",
    "            if finished:\n",
    "                break\n",
    "    \n",
    "    def start_preprocessing(self):\n",
    "        self.running = True\n",
    "        self.producer_thread = threading.Thread(target=self._image_processing_worker)\n",
    "        self.producer_thread.daemon = True\n",
    "        self.producer_thread.start()\n",
    "        print(\"Background producer started\")\n",
    "    \n",
    "    def stop_preprocessing(self):\n",
    "        self.running = False\n",
    "        if self.producer_thread:\n",
    "            self.producer_thread.join(timeout=10)\n",
    "        print(\"Background producer stopped\")    \n",
    "    \n",
    "    def preprocess_frames(self, num_frames: int):\n",
    "        \n",
    "        # Limit the queue size\n",
    "        if MAX_QUEUE_SIZE > 0:\n",
    "            while self.frame_queue.qsize() > MAX_QUEUE_SIZE - BATCH_SIZE:\n",
    "                sleep(QUEUE_SIZE_CHECK_INTERVAL)\n",
    "        \n",
    "        inference_frames = []\n",
    "        output_frames = []\n",
    "        skipped_frameses = []\n",
    "        finished = False\n",
    "        for _ in range(num_frames):\n",
    "            skipped_frames = self.skip_frames(self.get_allowed_frame_skip() - 1, collect_skipped=RENDER_SKIPPED_FRAMES)\n",
    "            skipped_frameses.append(skipped_frames)\n",
    "            ret, frame = self.cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                log(\"No more frames to read from video.\")\n",
    "                finished = True\n",
    "                break\n",
    "            # log(self.adjusted_width, self.adjusted_height)\n",
    "            inference_frame = cv2.resize(frame, (self.adjusted_width, self.adjusted_height))\n",
    "            \n",
    "            output_frame_width = int(PREVIEW_IMAGE_SIZE * self.aspect_ratio)\n",
    "            output_frame_height = PREVIEW_IMAGE_SIZE\n",
    "            output_frame = cv2.resize(frame, (output_frame_width, output_frame_height))\n",
    "            \n",
    "            inference_frames.append(inference_frame)\n",
    "            output_frames.append(output_frame)\n",
    "        log(f\"Camera {self.name}: Running inference on batch of {len(inference_frames)} frames.\")\n",
    "        if len(inference_frames) == 0:\n",
    "            return True\n",
    "        resultses = self.model.track(inference_frames, conf=0.25, persist=True, device=0, verbose=VERBOSE_YOLO)\n",
    "        # self.frame_count += num_frames\n",
    "        for i, results in enumerate(resultses):\n",
    "            if RENDER_SKIPPED_FRAMES and self.last_results is not None:\n",
    "                for skipped_frame in skipped_frameses[i]:\n",
    "                    self.results_queue.put(self.last_results)\n",
    "            self.results_queue.put(results)\n",
    "            self.last_results = results\n",
    "        for i, frame in enumerate(output_frames):\n",
    "            if RENDER_SKIPPED_FRAMES:\n",
    "                for skipped_frame in skipped_frameses[i]:\n",
    "                    self.frame_queue.put(skipped_frame)\n",
    "            self.frame_queue.put(frame)\n",
    "        return finished\n",
    "\n",
    "    def is_open(self):\n",
    "        return self.cap.isOpened()\n",
    "    \n",
    "    def release(self):\n",
    "        self.cap.release()\n",
    "        if SAVE_VIDEO and hasattr(self, 'out') and self.out is not None: \n",
    "            self.out.release()\n",
    "            log(f\"Camera {self.name}: Video saved to {self.output_path}\")\n",
    "        self.stop_preprocessing()\n",
    "    \n",
    "    def finish_frame(self):\n",
    "        self.processed_frame_count += 1\n",
    "        \n",
    "    def register_bottle(self, x, y, track_id):\n",
    "        if track_id in self.bottles:\n",
    "            self.bottles[track_id].x = x\n",
    "            self.bottles[track_id].y = y\n",
    "            return False\n",
    "        \n",
    "        if track_id in self.temporary_bottles:\n",
    "            self.track_ids_seen[track_id] += 1\n",
    "            self.temporary_bottles[track_id].x = x\n",
    "            self.temporary_bottles[track_id].y = y\n",
    "            if self.track_ids_seen[track_id] >= TEMPORAL_CUTOFF_THRESHOLD / self.get_allowed_frame_skip():\n",
    "                bottle = self.temporary_bottles[track_id]\n",
    "                self.bottle_index_counter += 1\n",
    "                bottle.index = self.bottle_index_counter\n",
    "                self.bottles[track_id] = bottle\n",
    "                log(\"Bottle assigned index:\", bottle.index, \"Track ID:\", track_id, \"Camera:\", self.name)\n",
    "                del self.temporary_bottles[track_id]\n",
    "                self.last_registered_bottle = bottle\n",
    "                self.last_registered_bottle_track_id = track_id\n",
    "                return True\n",
    "            return False\n",
    "        bottle = Bottle(x, y, track_id)\n",
    "        self.temporary_bottles[track_id] = bottle\n",
    "        self.track_ids_seen[track_id] = 1\n",
    "        \n",
    "        return False\n",
    "\n",
    "    def register_correction(self, corrected_index):\n",
    "        self.sequential_correction_count += 1\n",
    "        if self.sequential_correction_count > TEMPORAL_CUTOFF_THRESHOLD / self.get_allowed_frame_skip():\n",
    "            self.bottle_index_counter = corrected_index\n",
    "            log(f\"I, Camera {self.name}, was wrong {self.sequential_correction_count} in a row. I really thought I was right but I guess I wasn't. As punishment I will correct myself, remember that the correct index from now on is {corrected_index} and I will try my best to never do this again. I'm so sorry.\")\n",
    "\n",
    "class BottleTracker:\n",
    "    cameras: list[Camera]\n",
    "    track_ids: list[int]\n",
    "    bottle_was_entering: bool = False\n",
    "    \n",
    "    camera_disagreement_counts: dict[int, int] = {}\n",
    "    last_corrected_index: int = -1\n",
    "    \n",
    "    last_frame_time = time()\n",
    "    \n",
    "    def __init__(self, cameras: list[Camera]):\n",
    "        self.cameras = cameras\n",
    "        self.track_ids = []\n",
    "    \n",
    "    def run(self):\n",
    "        # For Jupyter: we'll use matplotlib for display instead of cv2.imshow\n",
    "        plt.ion()  # Interactive mode on\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))\n",
    "        \n",
    "        for camera in self.cameras:\n",
    "            camera.start_preprocessing()\n",
    "            \n",
    "        try:\n",
    "            while True:\n",
    "                frames = []\n",
    "                all_done = True\n",
    "                \n",
    "                for camera_index, camera in enumerate(self.cameras):\n",
    "                    if camera.processed_frame_count >= MAX_FRAMES or not camera.is_open():\n",
    "                        log(f\"Camera {camera.name} done. {camera.processed_frame_count} frames processed.\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        all_done = False\n",
    "                    \n",
    "                    frame = camera.render_frame()\n",
    "                    if frame is not None:\n",
    "                        frames.append(frame)\n",
    "                                    \n",
    "                # Check if all cameras agree with each other on the last bottle index\n",
    "                last_bottle_indices = set()\n",
    "                for camera in self.cameras:\n",
    "                    if camera.last_registered_bottle is not None:\n",
    "                        last_bottle_indices.add(camera.last_registered_bottle.index)\n",
    "                \n",
    "                if len(last_bottle_indices) > 1:\n",
    "                    # log(\"Warning: Cameras disagree on last registered bottle indices:\", last_bottle_indices, \"Camera number:\", camera_index)\n",
    "                    self.camera_disagreement_counts[camera_index] = self.camera_disagreement_counts.get(camera_index, 0) + 1\n",
    "                    \n",
    "                    if self.camera_disagreement_counts[camera_index] >= BOTTLE_DISAGREEMENT_TOLERANCE:\n",
    "                        self.correct_index_disagreements()\n",
    "                \n",
    "                # If the last frame was displayed recently, wait\n",
    "                now = time()\n",
    "                time_passed = now - self.last_frame_time\n",
    "                min_time_passed = 1 / DISPLAY_FRAMERATE\n",
    "                if time_passed < min_time_passed:\n",
    "                    sleep_time = min_time_passed - time_passed\n",
    "                    if sleep_time > 0:\n",
    "                        queued_frames = self.cameras[0].get_ready_frames_count() if self.cameras else 0\n",
    "                        blabber(f\"I'm being rate limited. {queued_frames} frames are already prepared. Sleeping for {sleep_time} seconds...\")\n",
    "                        sleep(sleep_time)\n",
    "                \n",
    "                self.last_frame_time = time()\n",
    "                \n",
    "                # Display the frame in Jupyter\n",
    "                if frames:\n",
    "                    try:\n",
    "                        camera_count = len(frames)\n",
    "                        frame_rows = self.split_array(frames, 2)\n",
    "                        row_frames = []\n",
    "                        for row in frame_rows:\n",
    "                            while len(row) < 2:\n",
    "                                # Create a black frame of the same dimensions\n",
    "                                row.append(np.zeros_like(row[0]))\n",
    "                            row_frame = np.hstack(row)\n",
    "                            row_frames.append(row_frame)\n",
    "                    \n",
    "                        combined_frame = np.vstack(row_frames)\n",
    "                        \n",
    "                        # Convert BGR to RGB for matplotlib\n",
    "                        combined_frame_rgb = cv2.cvtColor(combined_frame, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        # Clear and update the plot\n",
    "                        ax.clear()\n",
    "                        ax.imshow(combined_frame_rgb)\n",
    "                        ax.axis('off')\n",
    "                        ax.set_title('Live Bottle Tracking with Continuous OCR')\n",
    "                        plt.tight_layout()\n",
    "                        \n",
    "                        # Display in notebook\n",
    "                        fig.canvas.draw()\n",
    "                        IPython.display.display(fig)\n",
    "                        IPython.display.clear_output(wait=True)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        log(f\"Error displaying frames: {e}\")\n",
    "                \n",
    "                if all_done:\n",
    "                    log(\"All cameras finished processing.\")\n",
    "                    break\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            log(\"Interrupted by user\")\n",
    "        finally:\n",
    "            plt.ioff()\n",
    "            plt.close()\n",
    "            self.release()\n",
    "            \n",
    "            # Print OCR summary\n",
    "            self.print_ocr_summary()\n",
    "        \n",
    "    def print_ocr_summary(self):\n",
    "        \"\"\"Print a summary of all OCR results\"\"\"\n",
    "        if not USE_OCR or not os.path.exists(OCR_RESULTS_CSV):\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            df = pd.read_csv(OCR_RESULTS_CSV)\n",
    "            if df.empty:\n",
    "                log(\"No OCR results collected.\")\n",
    "                return\n",
    "                \n",
    "            log(\"\\n=== OCR Results Summary ===\")\n",
    "            log(f\"Total OCR entries: {len(df)}\")\n",
    "            log(f\"Unique bottles with OCR: {df['bottle_id'].nunique()}\")\n",
    "            \n",
    "            # Group by bottle_id and get best OCR result for each bottle\n",
    "            best_results = df.loc[df.groupby('bottle_id')['confidence'].idxmax()]\n",
    "            \n",
    "            log(\"\\nBest OCR results per bottle:\")\n",
    "            for _, row in best_results.iterrows():\n",
    "                # Count total attempts for this bottle\n",
    "                bottle_attempts = len(df[df['bottle_id'] == row['bottle_id']])\n",
    "                log(f\"Bottle {row['bottle_id']}: '{row['ocr_text']}' (confidence: {row['confidence']:.2f}, attempts: {bottle_attempts})\")\n",
    "                \n",
    "            # Show all unique texts found for each bottle\n",
    "            log(\"\\nAll unique OCR texts per bottle:\")\n",
    "            for bottle_id in df['bottle_id'].unique():\n",
    "                bottle_data = df[df['bottle_id'] == bottle_id]\n",
    "                unique_texts = bottle_data['ocr_text'].unique()\n",
    "                log(f\"Bottle {bottle_id}: {len(unique_texts)} unique texts\")\n",
    "                for text in unique_texts:\n",
    "                    if text.strip():  # Only show non-empty texts\n",
    "                        max_conf = bottle_data[bottle_data['ocr_text'] == text]['confidence'].max()\n",
    "                        log(f\"  - '{text}' (max confidence: {max_conf:.2f})\")\n",
    "                \n",
    "            log(f\"\\nFull results saved to: {OCR_RESULTS_CSV}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            log(f\"Error generating OCR summary: {e}\")\n",
    "        \n",
    "    def correct_index_disagreements(self):\n",
    "        # Find the most common last registered bottle index among cameras\n",
    "        log(\"Correcting index disagreements among cameras.\")\n",
    "        last_indices = []\n",
    "        for camera in self.cameras:\n",
    "            if camera.last_registered_bottle is not None:\n",
    "                last_indices.append(camera.last_registered_bottle.index)\n",
    "        log(\"Last registered bottle indices from cameras:\", last_indices)\n",
    "        if not last_indices:\n",
    "            return\n",
    "        \n",
    "        index_counts = Counter(last_indices)\n",
    "        most_common_index, most_common_count = index_counts.most_common(1)[0]\n",
    "        \n",
    "        log(f\"Most common last registered bottle index is {most_common_index} seen {most_common_count} times.\")\n",
    "        \n",
    "        if ENFORCE_INCREMENTAL_CORRECTION and not most_common_index > self.last_corrected_index:\n",
    "            log(\"Warning: I can't correct to an index that was used before. Incrementing might skip an index but ensures all indexes link to one bottle.\")\n",
    "            most_common_index = self.last_corrected_index + 1\n",
    "        \n",
    "        if most_common_count > len(self.cameras) / 2 or (EXTRA_CORRECTION and most_common_count == len(self.cameras) / 2):\n",
    "            log(\"Majority agreement found, correcting outcast.\")\n",
    "            self.last_corrected_index = most_common_index\n",
    "            for camera in self.cameras:\n",
    "                if camera.last_registered_bottle is not None:\n",
    "                    log(f\"Correcting camera {camera.name} from index {camera.last_registered_bottle.index} to {most_common_index}\")\n",
    "                    if camera.last_registered_bottle.index != most_common_index:\n",
    "                        camera.last_registered_bottle.index = most_common_index\n",
    "                        camera.last_registered_bottle.was_corrected = True\n",
    "                        camera.register_correction(most_common_index)\n",
    "                        \n",
    "        \n",
    "        # reset disagreement counts\n",
    "        self.camera_disagreement_counts = {}\n",
    "\n",
    "    # Boring functions\n",
    "\n",
    "    def split_array(self, arr, max_length):\n",
    "        return [arr[i:i + max_length] for i in range(0, len(arr), max_length)] if arr else []\n",
    "            \n",
    "    def release(self):\n",
    "        for camera in self.cameras: \n",
    "            camera.release()\n",
    "\n",
    "def main():\n",
    "    # Initialise the OCR reader \n",
    "    global OCR_READER\n",
    "    OCR_READER = initialize_ocr()\n",
    "    \n",
    "    cameras = [\n",
    "        Camera('Top', 'videos/14_55/14_55_top_cropped.mp4', start_delay=4),\n",
    "        Camera('Front', 'videos/14_55/14_55_front_cropped.mp4', start_delay=0),\n",
    "        Camera('Back Left', 'videos/14_55/14_55_back_left_cropped.mp4', start_delay=2),\n",
    "        Camera('Back Right', 'videos/14_55/14_55_back_right_cropped.mp4', start_delay=1, start_index=-1),\n",
    "    ]\n",
    "    \n",
    "    bottle_tracker = BottleTracker(cameras)\n",
    "    \n",
    "    log(\"Created cameras. Initiating tracking...\")\n",
    "    bottle_tracker.run()\n",
    "\n",
    "def run_tracking():\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d037c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Top done. 100 frames processed.\n",
      "Camera Front done. 100 frames processed.\n",
      "Camera Back Left done. 100 frames processed.\n",
      "Camera Back Right done. 100 frames processed.\n",
      "All cameras finished processing.\n",
      "Camera Top: Video saved to runs/detect/track/14_55_top_cropped_tracked.mp4\n",
      "Background producer stopped\n",
      "Camera Front: Video saved to runs/detect/track/14_55_front_cropped_tracked.mp4\n",
      "Background producer stopped\n",
      "Camera Back Left: Video saved to runs/detect/track/14_55_back_left_cropped_tracked.mp4\n",
      "Background producer stopped\n",
      "Camera Back Right: Video saved to runs/detect/track/14_55_back_right_cropped_tracked.mp4\n",
      "Background producer stopped\n",
      "Error generating OCR summary: Error tokenizing data. C error: Expected 3 fields in line 6, saw 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89c6bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created bottle_ocr_filtered_results.csv successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brech\\AppData\\Local\\Temp\\ipykernel_19272\\2280166518.py:9: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_df = df[df[\"ocr_text\"].str.contains(filter_pattern, regex=True, na=False)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"bottle_ocr_results.csv\")\n",
    "df[\"ocr_text\"] = df[\"ocr_text\"].astype(str)\n",
    "\n",
    "filter_pattern = r\"(KG|KG-\\d{4}|\\d{2}\\.\\d)\"\n",
    "filtered_df = df[df[\"ocr_text\"].str.contains(filter_pattern, regex=True, na=False)]\n",
    "\n",
    "\n",
    "tarra_pattern = r\"(\\d{2}\\.\\d(?:\\s?KG)?)\" # matches: 10.7 , 10.7 KG , 10.7KG\n",
    "year_pattern = r\"(KG-\\d{4}|\\d{4})\" # matches: KG-2034 , 2034\n",
    "\n",
    "results = []\n",
    "\n",
    "for bottle_id, group in filtered_df.groupby(\"bottle_id\"):\n",
    "\n",
    "    tarra_matches = set()\n",
    "    year_matches = set()\n",
    "\n",
    "    for text in group[\"ocr_text\"]:\n",
    "        tarra_matches.update(re.findall(tarra_pattern, text))\n",
    "        year_matches.update(re.findall(year_pattern, text))\n",
    "\n",
    "    results.append({\n",
    "        \"bottle_id\": bottle_id,\n",
    "        \"tarra\": \" \".join(sorted(tarra_matches)) if tarra_matches else None,\n",
    "        \"year\": \" \".join(sorted(year_matches)) if year_matches else None\n",
    "    })\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv(\"bottle_ocr_filtered_results.csv\", index=False)\n",
    "\n",
    "print(\"Created bottle_ocr_filtered_results.csv successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
